from __future__ import annotations

import argparse
import hashlib
import json
import time
from pathlib import Path
from typing import Any, Dict

from contracts.signs import SignRequest, SignResponse, Spec, ElectricalSpec, MechanicalSpec, GraphicsSpec
from svcs.common.fsqueue import FSQueue
from svcs.orchestrator.validate import validate_and_wrap, write_json_atomic, store_blob
from svcs.common.index import already_processed, append_processed
from svcs.orchestrator.events import Event, append_event


def process_file(root: Path, path: Path) -> None:
    payload = json.loads(path.read_text(encoding="utf-8"))
    task_id = payload.get("task_id", "unknown")
    trace_id = hashlib.sha256(json.dumps(payload, sort_keys=True).encode("utf-8")).hexdigest()[:16]
    out_dir = root / "runs" / task_id / "out"
    out_dir.mkdir(parents=True, exist_ok=True)

    # Minimal deterministic placeholder output; main logic resides in signs-service
    req = SignRequest.model_validate(payload)
    spec = Spec(materials=["5052-H32 Al"], finishes=["powdercoat"], ip_rating_target=None, enclosure_class=None)
    electrical = ElectricalSpec(disconnect="local lockable", max_input_current_A=0.1, branch_circuit_A=15.0, listing_category=None, required_field_labels=[])
    mech = MechanicalSpec(mounting_pattern="per drawing", min_fastener_grade="A2-70", sealants=["silicone RTV"], gasket_material=None)
    gfx = GraphicsSpec()
    result = SignResponse(
        spec=spec,
        electrical_spec=electrical,
        mechanical_spec=mech,
        graphics_spec=gfx,
        bom=[],
        cad_macro="# generated by agent_signs placeholder\n",
        install_notes=["Verify NEC 600 disconnect within sight"],
        compliance=[],
        risks=[],
    ).model_dump(mode="json")

    started = time.time()
    envelope = validate_and_wrap(
        raw=result,
        schema_model=SignResponse,
        agent="AGENT_SIGNS",
        version="0.1.0",
        code_sha="dev",
        started_at=started,
        inputs_bytes=json.dumps(payload, sort_keys=True).encode("utf-8"),
        schema_version="resp-1.0",
        blob_refs=[],
        queue_version="v1",
    )
    out_path = out_dir / "signs.json"
    write_json_atomic(out_path, envelope)
    append_event(root / "artifacts" / "logs" / "events.ndjson", Event(
        task_id=task_id,
        agent="signs",
        kind="completed",
        trace_id=envelope["trace"]["ids"]["trace_id"],
        span_id=envelope["trace"]["ids"]["span_id"],
        event="completed",
        monotonic_ms=envelope["provenance"]["monotonic_ms"],
        data_sha256=envelope["data_sha256"],
        blob_refs=envelope.get("blob_refs", []),
        message="signs processed",
    ))
    append_processed(root / "runs" / task_id, "AGENT_SIGNS", envelope["data_sha256"], envelope["trace"]["ids"]["trace_id"])


def main() -> None:
    parser = argparse.ArgumentParser(description="AGENT_SIGNS")
    parser.add_argument("--once", action="store_true", help="Process existing inbox once and exit")
    args = parser.parse_args()

    root = Path(".").resolve()
    inbox = root / "queue" / "signs" / "inbox"
    wip = root / "queue" / "signs" / "wip"
    out = root / "queue" / "signs" / "out"
    q = FSQueue(inbox, wip, out)

    def process_all() -> int:
        count = 0
        for p in q.poll():
            try:
                wip_file, fd, lock_path = q.claim(p)
            except RuntimeError:
                continue
            try:
                payload = json.loads(wip_file.read_text(encoding="utf-8"))
                task_dir = root / "runs" / payload.get("task_id", "unknown")
                if already_processed(task_dir, "AGENT_SIGNS"):
                    append_event(root / "artifacts" / "logs" / "events.ndjson", Event(
                        task_id=payload.get("task_id", "unknown"), agent="signs", kind="skipped_duplicate", trace_id="dup", span_id="dup", event="skipped_duplicate", monotonic_ms=0.0, data_sha256="", blob_refs=[], message="duplicate detected via processed index"
                    ))
                else:
                    process_file(root, wip_file)
                    count += 1
            finally:
                q.release(fd, lock_path)
        return count

    if args.once:
        process_all()
    else:
        while True:
            n = process_all()
            time.sleep(1.0 if n == 0 else 0.1)


if __name__ == "__main__":
    main()


